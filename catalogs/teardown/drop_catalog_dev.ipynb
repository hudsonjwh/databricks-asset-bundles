{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ecff171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metastore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>azure:southcentralus:61b8d794-ad5e-4abc-9a76-7e461df8e53c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[metastore: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "select current_metastore() metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5aff90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>citibikes_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>citibikes_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hive_metastore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[catalog: string]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql\n",
    "show catalogs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "use catalog citibike_dev;\n",
    "\n",
    "drop volume if exists source_citibike_data;\n",
    "\n",
    "drop schema if exists 00_landing;\n",
    "drop schema if exists 01_bronze;\n",
    "\n",
    "drop schema if exists 02_silver;\n",
    "drop schema if exists 03_gold;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d7c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[RequestId=297033bb-c239-4a58-9c25-2c05518fb6e7 ErrorClass=CATALOG_NOT_EMPTY] Catalog 'citibikes_dev' is not empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _sqldf\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m _sqldf = \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'''\u001b[39;49m\u001b[33;43mdrop catalog if exists citibikes_dev\u001b[39;49m\u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m _sqldf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/session.py:736\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m         _views.append(SubqueryAlias(df._plan, name))\n\u001b[32m    735\u001b[39m cmd = SQL(sqlQuery, _args, _named_args, _views)\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m data, properties, ei = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msql_command_result\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[32m    738\u001b[39m     df = DataFrame(CachedRelation(properties[\u001b[33m\"\u001b[39m\u001b[33msql_command_result\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1297\u001b[39m, in \u001b[36mSparkConnectClient.execute_command\u001b[39m\u001b[34m(self, command, observations, extra_request_metadata)\u001b[39m\n\u001b[32m   1295\u001b[39m     req.user_context.user_id = \u001b[38;5;28mself\u001b[39m._user_id\n\u001b[32m   1296\u001b[39m req.plan.command.CopyFrom(command)\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m data, _, metrics, observed_metrics, properties = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[38;5;66;03m# Create a query execution object.\u001b[39;00m\n\u001b[32m   1301\u001b[39m ei = ExecutionInfo(metrics, observed_metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1755\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, self_destruct)\u001b[39m\n\u001b[32m   1752\u001b[39m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {}\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Progress(handlers=\u001b[38;5;28mself\u001b[39m._progress_handlers, operation_id=req.operation_id) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch_as_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1756\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\n\u001b[32m   1757\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1758\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStructType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1759\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1731\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, progress)\u001b[39m\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m kb\n\u001b[32m   1730\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m-> \u001b[39m\u001b[32m1731\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:2047\u001b[39m, in \u001b[36mSparkConnectClient._handle_error\u001b[39m\u001b[34m(self, error)\u001b[39m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28mself\u001b[39m.thread_local.inside_error_handling = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2046\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, grpc.RpcError):\n\u001b[32m-> \u001b[39m\u001b[32m2047\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_rpc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2048\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   2049\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCannot invoke RPC\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode_projects/databricks/databricks-asset-bundles/dab_project/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:2149\u001b[39m, in \u001b[36mSparkConnectClient._handle_rpc_error\u001b[39m\u001b[34m(self, rpc_error)\u001b[39m\n\u001b[32m   2134\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m   2135\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mPython versions in the Spark Connect client and server are different. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2136\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mTo execute user-defined functions, client and server should have the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2145\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2146\u001b[39m                 )\n\u001b[32m   2147\u001b[39m             \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2149\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m convert_exception(\n\u001b[32m   2150\u001b[39m                 info,\n\u001b[32m   2151\u001b[39m                 status.message,\n\u001b[32m   2152\u001b[39m                 \u001b[38;5;28mself\u001b[39m._fetch_enriched_error(info),\n\u001b[32m   2153\u001b[39m                 \u001b[38;5;28mself\u001b[39m._display_server_stack_trace(),\n\u001b[32m   2154\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(status.message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAnalysisException\u001b[39m: [RequestId=297033bb-c239-4a58-9c25-2c05518fb6e7 ErrorClass=CATALOG_NOT_EMPTY] Catalog 'citibikes_dev' is not empty"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "drop catalog if exists citibike_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a901913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql\n",
    "use catalog citibikes_dev;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd70e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "create schema if not exists 00_landing;\n",
    "create schema if not exists 01_bronze;\n",
    "create schema if not exists 02_silver;\n",
    "create schema if not exists 03_gold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2fe603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>databaseName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_landing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[databaseName: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "show schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0720ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "use schema 00_landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef100554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "\n",
    "create volume if not exists source_citibike_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b597325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>volume_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[database: string, volume_name: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql \n",
    "show volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce13d66e",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (177749021.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m-- COPY INTO VOLUME citibikes_dev.00_landing.source_citibike_data\u001b[39m\n                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "-- %sql\n",
    "-- -- Example: copy files from cloud storage into a managed volume\n",
    "-- -- Replace <volume_name>, <cloud-uri>, and file format/options as appropriate.\n",
    "-- COPY INTO VOLUME citibikes_dev.00_landing.source_citibike_data\n",
    "-- FROM 'abfss://metastore@hudsonjwhdbricksmetastor.dfs.core.windows.net/metastorepath/citibikes/csv_data/citibike-tripdata.csv'\n",
    "-- FILEFORMAT = 'csv'   -- or 'csv'\n",
    "-- FORMAT_OPTIONS ('header'='true', 'inferSchema'='true')  -- for CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
