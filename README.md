# dab_project

The 'dab_project' project was generated by using the default-python template.

## Getting started

0. az login

1. run ../setup_teardown/databricks-<<env>>.sh

2. run ./clusters/create-cluster.sh

3. python3 -m venv .venv

4. source .venv/bin/activate

5. select python interpreter

6. configure the DEFAULT profile, and optionally, the other environments

7. change the host entry in the bundle's databricks.yml file

<!-- 8. databricks bundle init -->

<!-- 9. databricks bundle deploy -->

10. pip install databricks-connect==15.4

11. run ./catalogs/catalogs.sh

12. run the ./catalogs Jupyter notebooks for the catalogs


pip3 install setuptools
pip3 install wheel


## tearing dowm

1. run ../setup_teardown/teardown/delete-databricks-<<env>>.sh

## lessons learned

1. The cluster must be unity-catalog enabled (Advanced settings)





0. Install UV: https://docs.astral.sh/uv/getting-started/installation/

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure
    ```

3. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] dab_project_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

4. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

   Note that the default job from the template has a schedule that runs every day
   (defined in resources/dab_project.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

5. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```
6. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html.

7. For documentation on the Databricks asset bundles format used
   for this project, and for CI/CD configuration, see
   https://docs.databricks.com/dev-tools/bundles/index.html.
